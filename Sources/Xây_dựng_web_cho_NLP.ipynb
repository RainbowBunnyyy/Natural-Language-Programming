{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Khám phá dữ liệu"
      ],
      "metadata": {
        "id": "NyLg6H3sGC32"
      },
      "id": "NyLg6H3sGC32"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTnIii40Gj1u",
        "outputId": "f5490d81-79da-4911-8fa5-8774d6437efe"
      },
      "id": "fTnIii40Gj1u",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder = '/content/drive/MyDrive/Tài liệu học tập/HK5/Xử lý ngôn ngữ tự nhiên/NLP'"
      ],
      "metadata": {
        "id": "WlzBc8HVGnaE"
      },
      "id": "WlzBc8HVGnaE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q underthesea"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDMZmbDxLfeV",
        "outputId": "84fa2d4e-7544-43e1-fcab-4bd33c128897"
      },
      "id": "jDMZmbDxLfeV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "from underthesea import text_normalize\n",
        "import string\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
        "import underthesea\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "xjsPW2ZgGFj1"
      },
      "id": "xjsPW2ZgGFj1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_repeated_syllables(text):\n",
        "    # Sử dụng regex để tìm các từ có âm tiết lặp lại (ví dụ: quááááá)\n",
        "    repeated_syllables_pattern = re.compile(r'(\\w+?)\\1+', re.UNICODE)\n",
        "    # Hàm xử lý việc loại bỏ âm tiết lặp lại\n",
        "    def handle_repetition(match):\n",
        "        word = match.group(1)\n",
        "        # Giữ lại chỉ một phần lặp lại và thêm vào từ gốc\n",
        "        return word\n",
        "\n",
        "    # Áp dụng hàm xử lý vào chuỗi\n",
        "    processed_text = repeated_syllables_pattern.sub(handle_repetition, text)\n",
        "    return processed_text\n",
        "\n",
        "EMAIL = re.compile(r\"([\\w0-9_\\.-]+)(@)([\\d\\w\\.-]+)(\\.)([\\w\\.]{2,6})\")\n",
        "URL = re.compile(r\"https?:\\/\\/(?!.*:\\/\\/)\\S+\")\n",
        "PHONE = re.compile(r\"(09|01[2|6|8|9])+([0-9]{9})\\b\")\n",
        "MENTION = re.compile(r\"@.+?:\")\n",
        "NUMBER = re.compile(r'\\b\\d+\\S*\\b')\n",
        "DATETIME = '\\d{1,2}\\s?[/-]\\s?\\d{1,2}\\s?[/-]\\s?\\d{4}'\n",
        "\n",
        "# Delete price, 3g/4g/5g\n",
        "PRICE = r'\\b\\d{1,4}(?:\\.\\d{3})*(?:\\.\\d+)?(?:[ktrđg])\\b'\n",
        "\n",
        "def replace_common_token(txt):\n",
        "    txt = re.sub(EMAIL, ' ', txt)\n",
        "    txt = re.sub(URL, ' ', txt)\n",
        "    txt = re.sub(MENTION, ' ', txt)\n",
        "    txt = re.sub(DATETIME, ' ', txt)\n",
        "    txt = re.sub(NUMBER, ' ', txt)\n",
        "    txt = re.sub(PRICE, ' ', txt)\n",
        "    return txt\n",
        "\n",
        "def remove_unnecessary_characters(text):\n",
        "    RE_CLEAR = re.compile(\"[\\n\\r]+\")# Thay thế các chuỗi xuống dòng (\\n hoặc \\r) bằng một ký tự trắng\n",
        "    text = re.sub(RE_CLEAR, ' ', text)\n",
        "    # Sử dụng string.punctuation để lấy tất cả các ký tự dấu câu\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    # Loại bỏ dấu câu từ văn bản sử dụng bảng dịch (translator)\n",
        "    text = text.translate(translator)\n",
        "\n",
        "    return text\n",
        "\n",
        "def normalize_acronyms(text, teencode_file='/content/teencode.xlsx'):\n",
        "    # Đọc dữ liệu từ tệp Excel teencode.xlsx\n",
        "    teencode_df = pd.read_excel(teencode_file, header=None, names=['teencode', 'replace'])\n",
        "\n",
        "    words = []\n",
        "    for word in text.strip().split():\n",
        "        word = word.strip(string.punctuation)\n",
        "        # Tìm kiếm trong teencode_df và thay thế\n",
        "        replacement = teencode_df.loc[teencode_df['teencode'].str.lower() == word, 'replace'].values\n",
        "        if len(replacement) > 0:\n",
        "            words.append(replacement[0])\n",
        "        else:\n",
        "            words.append(word)\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "stopword = []\n",
        "with open('/content/stopword_train.txt', 'r', encoding='utf8') as fp:\n",
        "    for line in fp.readlines():\n",
        "        stopword.append(line.strip())\n",
        "len(stopword)\n",
        "\n",
        "# loại stopword khỏi dữ liệu\n",
        "def remove_stopwords(line):\n",
        "    words = []\n",
        "    for word in line.strip().split():\n",
        "        if word not in stopword:\n",
        "            words.append(word)\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Không tiến hành tách từ dính nhau vì bộ dữ liệu từ dính nhau chỉ được áp dụng cho bộ dữ liệu cũ, không bao quát cho dữ liệu mới nhập vào.\n",
        "def text_preprocess(text):\n",
        "    # 1. Chuẩn hóa văn bản tiếng việt\n",
        "    text = text_normalize(text)\n",
        "    # 2. Xử lý láy âm tiết\n",
        "    text = handle_repeated_syllables(text)\n",
        "    # 3. Loại bỏ các common token\n",
        "    text = replace_common_token(text)\n",
        "    # 4. Xóa bỏ dấu câu\n",
        "    text = remove_unnecessary_characters(text)\n",
        "    # 5. Đưa về lower\n",
        "    text = text.lower()\n",
        "    # 6. Chuẩn hóa các từ viết tắt cơ bản\n",
        "    text = normalize_acronyms(text)\n",
        "    # 7. Loại bỏ các stopword tiếng Việt\n",
        "    text = remove_stopwords(text)\n",
        "    # 8. Loại bỏ các khoảng trắng liên tiếp\n",
        "    RE_CLEAR = re.compile(\"\\s+\") # Các khoảng trắng liên tiếp\n",
        "    text = re.sub(RE_CLEAR,' ', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "bE1sfIUXQgJF"
      },
      "id": "bE1sfIUXQgJF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_rate(text):\n",
        "    text = text_preprocess(text)\n",
        "    text = underthesea.word_tokenize(text, format=\"text\")\n",
        "\n",
        "    balanced_df = pd.read_csv('/content/balanced_df.csv')\n",
        "    X, y = balanced_df['comment_token'], balanced_df['n_star']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    # Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
        "    count_vectorizer = CountVectorizer(ngram_range=(1, 5), stop_words=stopword, max_df=0.5, min_df=5)\n",
        "    tfidf_vectorizer = TfidfTransformer(use_idf=False, sublinear_tf = True, norm='l2', smooth_idf=True)\n",
        "\n",
        "    X_train = count_vectorizer.fit_transform(X_train)\n",
        "    X_train = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "    X_test = count_vectorizer.transform([text])\n",
        "    X_test = tfidf_vectorizer.transform(X_test)\n",
        "    # Dự đoán dữ liệu mới\n",
        "    maxent_model = joblib.load( '/content/maxent_model.pkl')\n",
        "    y_pre = maxent_model.predict(X_test)\n",
        "    return str(y_pre[0])"
      ],
      "metadata": {
        "id": "ad_We-2jpjgx"
      },
      "id": "ad_We-2jpjgx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio Demo: blocks_inputs"
      ],
      "metadata": {
        "id": "-qptvk7WcW3h"
      },
      "id": "-qptvk7WcW3h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "272996653310673477252411125948039410165",
      "metadata": {
        "id": "272996653310673477252411125948039410165"
      },
      "outputs": [],
      "source": [
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44380577570523278879349135829904343037",
      "metadata": {
        "id": "44380577570523278879349135829904343037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "outputId": "95320101-0c34-4b7d-b238-43e911f944a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caching examples at: '/content/gradio_cached_examples/40'\n",
            "Caching example 1/3\n",
            "Caching example 2/3\n",
            "Caching example 3/3\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://82dfaf43eefdf802e5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://82dfaf43eefdf802e5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def combine(a):\n",
        "    return predict_rate(a) + '⭐' # Chỗ này điền dự đoán của mô hình\n",
        "\n",
        "\n",
        "def mirror(x):\n",
        "    return x\n",
        "\n",
        "    import gradio as gr\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "\n",
        "    txt = gr.Textbox(label=\"Bạn thấy sản phẩm điện thoại này như thế nào\", lines=2)\n",
        "    txt_2 = gr.Textbox(value=\"\", label=\"Kết quả đánh giá\")\n",
        "    btn = gr.Button(value=\"Submit\")\n",
        "    btn.click(combine, inputs=[txt], outputs=[txt_2])\n",
        "    gr.Markdown(\"## Đánh giá ví dụ\")\n",
        "    gr.Examples(\n",
        "        [\"Tôi thấy sản phẩm này đẹp\", \"Cấu hình máy mạnh\", \"Máy chạy quá chậm\"],\n",
        "        [txt],\n",
        "        txt_2,\n",
        "        combine,\n",
        "        cache_examples=True)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.youtube.com/watch?v=WedtbRsT4cY"
      ],
      "metadata": {
        "id": "EOiUGAwNEghq"
      },
      "id": "EOiUGAwNEghq"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6kL0SSCCWsLE"
      },
      "id": "6kL0SSCCWsLE",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}